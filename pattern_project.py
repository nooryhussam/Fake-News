# -*- coding: utf-8 -*-
"""Pattern Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qj0mN6jQEecbYkI76TsAgCv-QTkIqiyI
"""

from google.colab import files
files.upload()  # Choose kaggle.json

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets list

!kaggle datasets download -d monal007/traindata
!unzip traindata.zip -d traindata

"""# Import Modules"""

#numeric operastions with array
import numpy as np
#handle dataset,loading dataset , (dataframe)
import pandas as pd
#clean regular expression
import re
#common word
from nltk.corpus import stopwords
#bring original word running-->run
from nltk.stem.porter import PorterStemmer
#convert text to numbers features (Term Frequency-Inverse Document Frequency)
from sklearn.feature_extraction.text import TfidfVectorizer
#split data to train and test
from sklearn.model_selection import train_test_split
#using logistic model (machine technique)
from sklearn.linear_model import LogisticRegression
#to calculate accuraccy
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

import nltk
nltk .download('stopwords')

#print the stop words in english
#these words doesn't add value dataset
print(stopwords.words('english'))

"""# Data Set"""

#loading the dataset to a pandas dataframe
news_dataset = pd.read_csv('/content/traindata/train.csv')

#number of rows and coloumn
news_dataset.shape

#print the first 5 rows of dataframe
news_dataset.head()

"""# Pre-processing


"""

#counting the number of missing value of the datset
news_dataset.isnull().sum()

# replacing the null values with empty string
news_dataset = news_dataset.fillna('')

#counting the number of missing value of the datset
news_dataset.isnull().sum()

# merging the author name and news title
news_dataset['content'] = news_dataset['author']+' '+news_dataset['title']

print(news_dataset['content'])

# separating the data & label
X = news_dataset.drop(columns='label', axis=1)
Y = news_dataset['label']

print(X)

print(Y)

"""# Stemming
Stemming is the process of reducing a word to its Root word example: actor, actress, acting --> act
"""

port_stem=PorterStemmer()

def stemming(content):
 stemmd_content=re.sub('[^a-zA-Z]',' ',content)
 stemmd_content= stemmd_content.lower()
 stemmd_content= stemmd_content.split()
 stemmd_content=[port_stem.stem(word) for word in stemmd_content if not word in stopwords.words('english') ]
 stemmd_content= ' '.join(stemmd_content)
 return stemmd_content

news_dataset['content']=news_dataset['content'].apply(stemming)

print(news_dataset['content'])

#separating the data and label
X = news_dataset['content'].values
Y = news_dataset['label'].values

print(X)

Y.shape

"""# Feature Extraction"""

# converting the textual data to numerical data
vectorizer=TfidfVectorizer(ngram_range=(1,1))   # يعني بيقيس أهمية كل كلمة في كل جملة مقارنة بباقي الجمل.
# Fit the vectorizer on the original text data 'X' before it was transformed
vectorizer.fit(news_dataset['content']) # Use the original 'content' column from the DataFrame

# Transform the text data into numerical features
X=vectorizer.transform(news_dataset['content'])

print(X)

"""# Split Train/Test"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify=Y, random_state=2)

"""# Model-->Logistic Regression without using PCA"""

# Logistic Regression
log_reg = LogisticRegression(C=0.01,max_iter=1000)
log_reg.fit(X_train, Y_train)

X_train_prediction = log_reg.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)
print(f'Accuracy score of Logistic Regression on training data: {training_data_accuracy * 100:.2f}%')

X_test_prediction = log_reg.predict(X_test)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)
print(f'Accuracy score of Logistic Regression on testing data: {test_data_accuracy * 100:.2f}%')

"""# **Model** with PCA"""

# Import PCA from sklearn.decomposition
from sklearn.decomposition import PCA

pca = PCA(n_components=500)
X_train_pca = pca.fit_transform(X_train)
X_test_pca = pca.transform(X_test)

# Logistic Regression
log_reg = LogisticRegression()
log_reg.fit(X_train_pca, Y_train)

X_train_prediction = log_reg.predict(X_train_pca)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)
print(f'Accuracy score of Logistic Regression on training data: {training_data_accuracy * 100:.2f}%')

X_test_prediction = log_reg.predict(X_test_pca)
test_data_accuracy = accuracy_score(Y_test, X_test_prediction)
print(f'Accuracy score of Logistic Regression on testing data (with PCA): {test_data_accuracy * 100:.2f}%')

from sklearn.manifold import TSNE

def visualize_tsne(X, Y, title):
    tsne = TSNE(n_components=2, random_state=42, perplexity=40, n_iter=300)
    X_embedded = tsne.fit_transform(X.toarray() if hasattr(X, 'toarray') else X)

    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=X_embedded[:, 0], y=X_embedded[:, 1], hue=Y, palette='Set1', alpha=0.7)
    plt.title(title)
    plt.xlabel('Component 1')
    plt.ylabel('Component 2')
    plt.legend(title='Label', loc='best')
    plt.grid(True)
    plt.show()

# Visualize before PCA
visualize_tsne(X, Y, "t-SNE Visualization BEFORE PCA")

"""# GUI"""

!pip install gradio

import gradio as gr

def predict_news(text):
    processed_text = stemming(text)
    X_new = vectorizer.transform([processed_text])
    X_new_pca = pca.transform(X_new.toarray())
    prediction = log_reg.predict(X_new_pca)
    return "This is Real News" if prediction[0] == 0 else "This is Fake News"

# Custom CSS
css = """
body {
    background-color: #f0f2f5;
}

h1 {
    color: #333366;
    text-align: center;
}

.description {
    font-size: 20px !important;
    font-weight: bold !important;
    color: #444444 !important;
    text-align: center !important;
}

textarea {
    background-color:#000000;
    border: 2px solid #333366;
    border-radius: 8px;
}

button {
    background-color: #333366 !important;
    color: white !important;
    border-radius: 8px !important;
    font-weight: bold !important;
}
"""

# Gradio Interface
interface = gr.Interface(
    fn=predict_news,
    inputs=gr.Textbox(lines=5, placeholder="Enter news text here..."),
    outputs=gr.Textbox(),
    title="📰 Fake News Detector",
    description="Enter news text below and the model will predict whether it's Real or Fake!",
    css=css,
    allow_flagging="never",
)

interface.launch(debug=True)